{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8177cbcb-b60c-484b-b10c-1b267e6e9cd8",
   "metadata": {},
   "source": [
    "# Quickstart: From dataset to predictions and evaluation\n",
    "\n",
    "This tutorial works with a sample dataset (with only one document) that is present in the repo (no need to download anything). To see how to properly work with larger datasets, check [Load and Sample Dataset](load_and_sample_dataset.md) tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc7cda7-5eb8-4faf-b616-620fc7693118",
   "metadata": {},
   "source": [
    "## Load sample dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2493c86a-3ab0-4d0d-bf86-b1f61e93b6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from docile.dataset import CachingConfig, Dataset\n",
    "\n",
    "DATASET_PATH = Path(\"/app/tests/data/sample-dataset/\")\n",
    "sample_dataset = Dataset(\"dev\", DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f4562f-ebb2-4c5d-a966-bb5ab635db30",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{sample_dataset} with {len(sample_dataset)} docs and {sample_dataset.total_page_count()} pages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a993cafb-ae3e-4a21-84f8-c9a67b31653d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_doc = sample_dataset[0]\n",
    "print(sample_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d883ec87-1b83-4aa2-af65-3f4566ca991d",
   "metadata": {},
   "source": [
    "## Browse available document resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c0bdf0-7249-405f-9400-19cdae6f775b",
   "metadata": {},
   "source": [
    "**Read pdf and convert it to image**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b118147f-83cc-4fa9-badb-834d53357016",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_bytes = sample_doc.data_paths.pdf_path(sample_doc.docid).read_bytes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061d5264-a23b-43c0-ae0f-7de4fa22f4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_bytes[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c919455f-eb56-4874-8cdd-edd064be987f",
   "metadata": {},
   "source": [
    "Convert to image with a width set to 500 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93790d69-6907-4f28-a9ad-aedfbb09d463",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_doc.page_image(page=0, image_size=(500, None))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cad8ad1-d376-4cf0-93c9-5bf6fb3f84fe",
   "metadata": {},
   "source": [
    "**Access & visualize annotations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f4877d-9dfc-4433-ba63-4b180ca6ba6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{sample_doc.annotation.fields[0]=}\\n\")\n",
    "print(f\"{sample_doc.annotation.li_fields[0]=}\\n\")\n",
    "print(f\"{sample_doc.annotation.li_headers[0]=}\\n\")\n",
    "print(f\"{sample_doc.annotation.cluster_id=}\")\n",
    "print(f\"{sample_doc.annotation.document_type=}\")\n",
    "print(f\"{len(sample_doc.annotation.get_table_grid(page=0).rows_bbox_with_type)=}\")\n",
    "print()\n",
    "print(\"Access raw annotations dictionary:\")\n",
    "print(f\"{sample_doc.annotation.content.keys()=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf07a60-0a26-4d4f-9b1e-edab08ebbb28",
   "metadata": {},
   "source": [
    "Show annotations in the dataset browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea35e9d-3fbd-4287-857f-ed6d4677427f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docile.tools.dataset_browser import DatasetBrowser\n",
    "\n",
    "browser = DatasetBrowser(sample_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92bb6c5-08d3-45bb-85e9-5588b7c7a954",
   "metadata": {},
   "source": [
    "**Access Pre-computed OCR**\n",
    "\n",
    "Word tokens of the pre-computed OCR can be easily accessed in two variants, with `snapped=False` and `snapped=True`. The first version is computed by DocTR and the second version uses some heuristics to remove whitespace around the edges of the predictions. The snapped OCR word boxes are also used to generate the Pseudo-Character-Centers which are used in evaluation (check the dataset paper or code for details)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557e8ec8-06ce-4079-af08-dfce3d87f338",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = sample_doc.ocr.get_all_words(page=0)\n",
    "snapped_words = sample_doc.ocr.get_all_words(page=0, snapped=True)\n",
    "print(words[0])\n",
    "print(snapped_words[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830c23e0-4b21-4e4d-9e3b-da64eef2a219",
   "metadata": {},
   "source": [
    "Show crop of the document page with pre-computed OCR words. Blue boxes are the original boxes, red boxes are the snapped boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00d4857-a08c-42d7-b418-7a10b95d4c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageDraw\n",
    "\n",
    "page_img = sample_doc.page_image(0, image_size=(1600, None))\n",
    "\n",
    "draw_img = page_img.copy()\n",
    "draw = ImageDraw.Draw(draw_img, \"RGB\")\n",
    "for word in sample_doc.ocr.get_all_words(page=0, snapped=False):\n",
    "    scaled_bbox = word.bbox.to_absolute_coords(*draw_img.size)\n",
    "    draw.rectangle(scaled_bbox.to_tuple(), outline=\"blue\")\n",
    "for word in sample_doc.ocr.get_all_words(page=0, snapped=True):\n",
    "    scaled_bbox = word.bbox.to_absolute_coords(*draw_img.size)\n",
    "    draw.rectangle(scaled_bbox.to_tuple(), outline=\"red\")\n",
    "draw_img.crop((680, 480, 950, 580))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1dd53f9-60ed-46d7-9a2f-62338bd0d9d0",
   "metadata": {},
   "source": [
    "Access raw OCR content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa6166a-8b25-4149-b768-22ae30760310",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ocr_dict = sample_doc.ocr.content\n",
    "ocr_dict[\"pages\"][0][\"blocks\"][4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174ff41e-34e6-42f0-a88b-0d6a675677cf",
   "metadata": {},
   "source": [
    "## Create dummy predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350f43f4-45f3-41e6-806d-3f4478733f9f",
   "metadata": {},
   "source": [
    "Create predictions as perturbations of the gold labels (just as example). Some labels are thrown away and for some labels, two predictions are created instead of one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2254249c-00e0-4b42-93c1-24772b7c0a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import replace\n",
    "from random import Random\n",
    "from typing import List, Sequence, Tuple\n",
    "\n",
    "from docile.dataset import BBox, Document, Field\n",
    "\n",
    "def fields_perturbation(rng: Random, fields: Sequence[Field], max_shift: Tuple[float, float]) -> List[Field]:\n",
    "    new_fields = []\n",
    "    for field in fields:\n",
    "        p = rng.random()\n",
    "        generate_fields = 1\n",
    "        if p < 0.2:\n",
    "            generate_fields = 0\n",
    "        elif p > 0.9:\n",
    "            generate_fields = 2\n",
    "        for _ in range(generate_fields):\n",
    "            max_shift_horizontal, max_shift_vertical = max_shift\n",
    "            left = field.bbox.left + (rng.random() * 2 - 1) * max_shift_horizontal\n",
    "            right = field.bbox.right + (rng.random() * 2 - 1) * max_shift_horizontal\n",
    "            if right < left:\n",
    "                left, right = right, left\n",
    "            top = field.bbox.top + (rng.random() * 2 - 1) * max_shift_vertical\n",
    "            bottom = field.bbox.bottom + (rng.random() * 2 - 1) * max_shift_vertical\n",
    "            if bottom < top:\n",
    "                top, bottom = bottom, top\n",
    "            new_field = replace(field, bbox=BBox(left, top, right, bottom))\n",
    "            new_fields.append(new_field)\n",
    "    return new_fields\n",
    "        \n",
    "def get_max_shift_in_relative_coords(doc: Document, max_shift_px_at_200dpi: Tuple[int, int]) -> Tuple[float, float]:\n",
    "    size_at_200dpi = doc.page_image_size(page=0, dpi=200)\n",
    "    return (max_shift_px_at_200dpi[0] / size_at_200dpi[0], max_shift_px_at_200dpi[1] / size_at_200dpi[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0389ec2b-352b-4cd7-8941-897755e7854d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = Random(42)\n",
    "\n",
    "max_shift = get_max_shift_in_relative_coords(sample_doc, max_shift_px_at_200dpi=(15, 5))\n",
    "kile_predictions = {sample_doc.docid: fields_perturbation(rng, sample_doc.annotation.fields, max_shift)}\n",
    "lir_predictions = {sample_doc.docid: fields_perturbation(rng, sample_doc.annotation.li_fields, max_shift)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4558af-4e87-42a8-8dad-cc86fbbab79d",
   "metadata": {},
   "source": [
    "**Store predictions to json**\n",
    "\n",
    "In this format predictions are submitted to the benchmark. With the predictions stored on disk you can also run the evaluation from command line with `docile_evaluate` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92e88a6-a595-487b-9658-5846dca4b47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docile.dataset import store_predictions\n",
    "\n",
    "store_predictions(Path(\"/tmp/kile-perturbations.json\"), kile_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c02db0d-d287-4fd1-a156-ae76c0f27003",
   "metadata": {},
   "source": [
    "**Run evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300848d4-a189-4f55-b85e-abc7d8acf420",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docile.evaluation import evaluate_dataset\n",
    "\n",
    "evaluation_result = evaluate_dataset(sample_dataset, kile_predictions, lir_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ddfa00-cb77-434d-a37e-67ada6245af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(evaluation_result.print_report())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7fd8ff-3fdb-4d5c-adea-d10addbfeb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_result.get_primary_metric(\"kile\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09249bee-7857-4743-84bd-94d6156d5c24",
   "metadata": {},
   "source": [
    "**Visualize matching**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771d46f9-c728-483a-94a7-3a664512fec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "kile_matching = evaluation_result.task_to_docid_to_matching[\"kile\"]\n",
    "lir_matching = evaluation_result.task_to_docid_to_matching[\"lir\"]\n",
    "DatasetBrowser(sample_dataset, kile_matching=kile_matching, lir_matching=lir_matching)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
